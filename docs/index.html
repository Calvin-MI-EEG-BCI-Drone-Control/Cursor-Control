<!DOCTYPE html>
<head>
    <title>Cursor Control BCI</title>
    <link rel="stylesheet" href="index.css">
</head>

<body>
    <header>
        <a href="https://computing.calvin.edu/" target="_blank">
            <img src="assets/calvin.jpg" alt="Calvin University Computer Science Department" class="logo" id="calvin-logo">
            <!-- https://cdn.theorg.com/f1019a4f-0f87-4b0e-aaaf-a7488b614d17_thumb.jpg -->
        </a>
        <p>Cursor Control Brain Computer Interface<p>
        <a href="https://github.com/Calvin-MI-EEG-BCI-Drone-Control/Cursor-Control/" target="_blank">
            <img src="assets/github.png" alt="GitHub Repository" class="logo" id="github-logo">
            <!-- https://1000logos.net/wp-content/uploads/2021/05/GitHub-logo.png -->
        </a>
    </header>
    <section id="vision-section">
        <h1>Vision Statement</h1>
        <p>
            My project involves the creation of a brain-computer interface that allows a user to control a computer cursor using motor imagery (imagined body movements). 
            Although the specific task of controlling a cursor using neural signals may not seem practical, this way of interfacing with technology is very significant. 
            For individuals that cannot interact with technology in a typical manner (because, for example, they are paralyzed or have limited mobility), 
            a brain-computer interface acts as a new, accessible method for controlling computers since it does not depend on the user’s physical abilities. 
            With this advantage of brain-computer interfaces in mind, I have chosen to utilize motor imagery rather than physical movement to control the cursor – 
            so that it could be used by anyone regardless of their motor abilities.
        </p>
        <p>
            The core of my solution is a machine learning model that infers cursor controls based on the user’s brain activity. 
            I am recording neural signals from an electroencephalography (EEG) cap and have created a pipeline for processing that data so that it can be used as input for the model. 
            The outputs of the model will be commands for how the cursor should move. 
        </p>
        <p>
            From the user’s point of view, they will be imagining themselves moving a certain part of their body in order to execute a command for the cursor 
            (for example, I could imagine moving my right arm and that could cause the cursor to move to the right). This is a control method that has been used for many related works.
            Using machine learning, I will be able to classify brain activity as matching certain imagined movements.
        </p>
    </section>
    <section id="resources-section">
        <h1>Resources</h1>
        <div>
            <a href="https://docs.google.com/document/d/1w8ms7MjL_fmp0HHNY3SvUYqzXm6JsQwqJlFdckH33Tk/edit?usp=sharing" target="_blank">Project Report</a>
        <a href="https://docs.google.com/presentation/d/1wWtqxy_lhzColIgHFLfVCISl200AxkFNlUZx4oPomDQ/edit?usp=sharing" target="_blank">Final Presentation</a>
        </div>
    </section>
    <section id="contributors-section">
        <h1>Contributors</h1>
        <div>
            <h2>Steven McKelvey</h2>
            <p>
                A computer science major and psychology minor with an interest in brain-computer interfacing.
                Proposed the idea of creating a BCI for a senior project and is the student leading the 
                development of this system.
            </p>
        </div>
        <div>
            <h2>Dr. Kenneth Arnold</h2>
            <p>
                Professor of computer science and data science at Calvin University with an interest in 
                artificial intelligence, language models, and human-computer interaction. He is the computer science
                advisor for this project, assisting with any AI and programming related tasks.
            </p>
        </div>
        <div>
            <h2>Dr. Paul Moes</h2>
            <p>
                Professor of psychology at Calvin University with an interest in neuroscience, particularly the
                corpus callosum and its role in the integration of activity between the left and right cerebral hemispheres.
                He has served as an advisor in this project by providing EEG equipment/software along with insights into
                working with neural signals and experimental design for determining how a user should interact with our system.
            </p>
        </div>
    </section>
</body>

</html>